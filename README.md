# ğŸ¤– AgentSystem

**Distributed AI orchestration system optimized for edge computing**

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Raspberry Pi](https://img.shields.io/badge/Raspberry%20Pi-5-red.svg)](https://www.raspberrypi.com/)

---

## What is AgentSystem?

AgentSystem is a distributed AI framework designed to run AI workloads across multiple devices, from high-performance servers to edge devices like Raspberry Pi 5. It uses Celery for task distribution, supports multiple AI providers (OpenAI, Gemini, OpenRouter, xAI), and features autonomous operations with memory persistence.

**Key Features:**
- ğŸš€ **Distributed Task Queue** â€” Celery-powered task distribution across multiple workers
- ğŸ§  **Multi-Provider AI** â€” Seamless switching between OpenAI, Gemini, OpenRouter, xAI, and local models
- ğŸ”„ **Autonomous Operations** â€” Self-managing tasks with memory and context persistence
- ğŸ“¡ **Edge Optimized** â€” Runs efficiently on Raspberry Pi 5 with AI HAT+
- ğŸ“Š **Real-Time Streaming** â€” WebSocket-based streaming for AI responses
- ğŸ’¾ **Memory System** â€” Persistent conversation history and context management
- âš¡ **Multimodal Support** â€” Text, image, and vision model integration

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Main Server   â”‚  â† Central coordinator (Redis + Flask/FastAPI)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         â”‚        â”‚        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”
â”‚Worker1â”‚ â”‚Worker2â”‚ â”‚ Pi5  â”‚ â”‚ Pi5  â”‚  â† Distributed workers
â”‚(Cloud)â”‚ â”‚(Local)â”‚ â”‚Workerâ”‚ â”‚Workerâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Start

### Prerequisites
- **Python 3.9+**
- **Redis** (for task queue)
- **API Keys** (OpenAI, Gemini, or other supported providers)

### Installation

```bash
# Clone the repository
git clone https://github.com/ereezyy/AgentSystem.git
cd AgentSystem

# Install dependencies
pip install -r requirements-prod.txt

# Configure environment
cp .env.example .env
nano .env  # Add your API keys and Redis URL
```

### Running a Worker

```bash
# Start a Celery worker
celery -A AgentSystem.core.celery_app worker --loglevel=info
```

### Raspberry Pi 5 Deployment

See [INSTALL.md](INSTALL.md) for detailed Pi5 setup instructions.

---

## Supported AI Providers

| Provider    | Text | Vision | Streaming | Local |
|-------------|------|--------|-----------|-------|
| OpenAI      | âœ…   | âœ…     | âœ…        | âŒ    |
| Gemini      | âœ…   | âœ…     | âœ…        | âŒ    |
| OpenRouter  | âœ…   | âœ…     | âœ…        | âŒ    |
| xAI (Grok)  | âœ…   | âŒ     | âœ…        | âŒ    |
| Local (Pi5) | âœ…   | âŒ     | âŒ        | âœ…    |

---

## Project Structure

```
AgentSystem/
â”œâ”€â”€ core/                    # Core system modules
â”‚   â”œâ”€â”€ celery_app.py       # Celery configuration
â”‚   â”œâ”€â”€ memory.py           # Memory persistence
â”‚   â””â”€â”€ config.py           # System configuration
â”œâ”€â”€ services/                # AI provider integrations
â”‚   â”œâ”€â”€ ai_providers/       # OpenAI, Gemini, xAI, etc.
â”‚   â”œâ”€â”€ ai.py               # Main AI service
â”‚   â””â”€â”€ streaming_service.py
â”œâ”€â”€ autonomous/              # Autonomous operations engine
â”œâ”€â”€ modules/                 # Feature modules
â”œâ”€â”€ utils/                   # Utility functions
â”œâ”€â”€ docs/                    # Documentation
â””â”€â”€ tests/                   # Test suite
```

---

## Configuration

Key environment variables:

```bash
# Redis (required)
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# AI Providers (at least one required)
OPENAI_API_KEY=your_openai_key
GOOGLE_API_KEY=your_gemini_key
OPENROUTER_API_KEY=your_openrouter_key
XAI_API_KEY=your_grok_key

# Worker Settings
CELERY_WORKER_CONCURRENCY=4  # Adjust based on hardware
```

---

## Use Cases

- **Multi-device AI workloads** â€” Distribute heavy AI tasks across multiple machines
- **Edge AI deployments** â€” Run AI on Raspberry Pi clusters for cost-effective inference
- **AI agent orchestration** â€” Build autonomous agents with memory and task queuing
- **Hybrid cloud/edge setups** â€” Combine cloud GPUs with local edge devices

---

## Performance

| Device          | Workers | Tasks/min | Avg Response Time |
|-----------------|---------|-----------|-------------------|
| Pi5 (4GB)       | 2       | ~30       | 2-5s              |
| Pi5 w/ AI HAT+  | 2       | ~50       | 1-3s              |
| Server (8-core) | 8       | ~200      | 0.5-1s            |

---

## Documentation

- [Installation Guide](INSTALL.md)
- [Backend Deployment](BACKEND_DEPLOYMENT_GUIDE.md)
- [Microcopy Analysis](MICROCOPY_ANALYSIS.md)

---

## Roadmap

- [ ] **Multi-modal RAG** â€” Knowledge base integration
- [ ] **Web UI** â€” Dashboard for monitoring workers
- [ ] **Auto-scaling** â€” Dynamic worker allocation
- [ ] **Function calling** â€” Tool use for autonomous agents
- [ ] **Voice support** â€” Speech-to-text/text-to-speech

---

## Contributing

Pull requests welcome. For major changes, open an issue first.

---

## License

MIT License - see [LICENSE](LICENSE) for details.

---

## Author

**Eddy Woods** ([@ereezyy](https://github.com/ereezyy))  
*AI Engineer & Game Developer*

---

**â­ Star this repo if you find it useful!**
